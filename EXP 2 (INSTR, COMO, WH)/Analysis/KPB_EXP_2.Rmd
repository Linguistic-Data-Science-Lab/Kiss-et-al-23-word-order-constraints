---
title: "EXP 2 (Kiss, Pieper, Börner 2023)"
output:
  html_document: default
  pdf_document: default
date: "23.03.2023"
---

### Analysis of experimental study on object-oriented and subject-oriented modifiers

This document provides the analysis for the experimental study on object-oriented and subject-oriented event-internal modifiers with alternating wh-indefinites and full indefinite NPs discussed in Kiss, Pieper, Börner (2023) (EXP 2).

#### Read in required libraries

```{r libraries, warning=FALSE, message=FALSE}
library(lme4)
library(tidyverse)
library(emmeans) 
library(kableExtra)
library(brms)  

show(version)
```

### Read in data

We provide a summary of the data. The test items contained in the data set are pretty-printed below.

```{r read-in data}
data <-
  read.csv("../Data/EXP_2_test.csv", 
           fileEncoding = "UTF-8", stringsAsFactors = TRUE) %>%
  mutate(OBJform = relevel(OBJform, ref = "NP"),                    # reference level for OBJform
         subjects = factor(workerId),
         items = factor(ITEM_ID))

## The reference level for TYPE is taken to be COM(O)

summary(subset(data, select = -c(OPTION_0_ITEM, OPTION_1_ITEM, OPTION_0_KEY_CONDITION, 
                                 OPTION_1_KEY_CONDITION, date_time_begin, date_time_end, 
                                 workerId, ITEM_ID)))

```

### Test items

The following table provides the 24 minimal pairs of test items used in EXP 2. The experimental data have been judged by 31 participants after filtering unattentive participants according to Pieper et al. (2023).  

```{r read in test items for presentation, echo = FALSE, message = FALSE}

data.sum <- data %>%
  select(items, TYPE, OPTION_0_ITEM, OPTION_1_ITEM) %>%
  group_by(items, TYPE, OPTION_0_ITEM, OPTION_1_ITEM) %>%
  summarize(count = n())

colnames(data.sum)[1:4] <- c("Test Item Pair", "Adverbial Type", "PP < OBJ", "OBJ < PP")

kbl(data.sum[,1:4]) %>% kable_styling()

```

#### Empirical distribution of choices

The following plot shows the distribution of empirical choices of the serializations (`PP > OBJ`, `OBJ > PP`) across the two different forms of the object (`Full NP indefinite`, `wh-indefinite`). 

We observe a difference in distribution between full indefinite NPs and wh-indefinites insofar as the distribution of the latter is similar across types, while the former shows clear differences between `INSTR` and `COM(O)`. Regarding the research question, it is of particular interest that the number of `OBJ > PP` serializations for `INSTR` is higher for `wh-indefinites` than for `full indefinite NPs`. A theoretical analysis relying on scrambling would have assumed that `OBJ > PP` could not occur with wh-indefinites, given a base position of the adverbial above the object. 

```{r empirical distribution, message = FALSE}

summary <- 
  data %>% 
  group_by(TYPE, OBJform, ANSWER) %>% 
  summarise(count=n())

summary

form.labels <- c("Full NP indefinite", "wh-indefinite")
names(form.labels) <- c("NP", "wh")


ggplot(summary, aes(x = TYPE, y = count, fill = ANSWER)) +
  geom_bar(stat = "identity", position = "dodge") + 
  labs(x = "Adverbial Type", y = "Frequency of Choice") +
  scale_fill_manual(name = "Choice", values = c("OBJ>PP" = "grey40","PP>OBJ" = "grey80"),
                    labels = c("OBJ < PP", "PP < OBJ")) + 
  facet_wrap(~OBJform, labeller = labeller(OBJform = form.labels))

```

```{r, echo = FALSE, message = FALSE}

ggsave("../Figures/EXP_2.emp_dist.pdf")

```

### Random slope model 

In the following, we define a random slope model (random slopes for the interaction of both predictors) for participants, and a random intercept model for items (which do not vary across conditions). 
Please notice that the random structure for subjects does not assume intercepts, because we want to obtain information on by-subject variance for each condition. To avoid a possibly spurious convergence warning for the model, we use a wrapper to access a non-linear optimizer from the library `nloptr`. For a general assessment of possibly spurious convergence warning see https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html and particularly https://joshua-nugent.github.io/allFit/. 


```{r models with interaction, message = FALSE, warning = FALSE}

model <- glmer(ANSWER ~ TYPE * OBJform +
                 (0 + TYPE * OBJform | subjects) + (1 | items),
               data = data, family = "binomial",
               control = glmerControl(
                 optimizer = "nloptwrap",
                 optCtrl = list(algorithm = "NLOPT_LN_NELDERMEAD")))

summary(model)

```

We notice that all coefficients show significant effects. It is not particularly surprising that `COM(O)` strongly prefers `OBJ > PP`. In the following, we use `emmeans` to calculate the model predictions, which are also printed together with their 95 % CIs. 

```{r model predictions}

results <- emmeans(model, pairwise~OBJform * TYPE , type = "response")

results$emmeans

emmip(model, TYPE ~ OBJform, type = "response", CIs = TRUE, 
      xlab = "Form of OBJ", ylab = "Prediction for PP > OBJ")

ggsave("../Figures/EXP_2.preds.pdf")

```

In the following, we compare the model with interactions to a model with the same random structure, but without interactions. The difference between the two models is significant.

```{r model comparison, message = FALSE}

model_2 <- glmer(ANSWER ~ TYPE + OBJform +
                     (0 + TYPE * OBJform | workerId) +
                     (1|ITEM_ID), data = data, family = "binomial",
                   control=glmerControl(optimizer = "nloptwrap",
                                        optCtrl = list(algorithm = "NLOPT_LN_NELDERMEAD")))

anova(model_2, model, test = "Chisq")

```

The following Bayesian model is included to provide more information about the likelihood distribution of the predictors. We have included a calculation of the region of practical equivalence (ROPE). For three of the four coefficients, it can be rejected that they do not show an effect (`COM(O)/NP`, `INSTR/NP`, `INSTR/wh`). 

We notice the warning, but it is unclear whether we should consider it or not, see: 
https://github.com/easystats/bayestestR/discussions/555 and https://easystats.github.io/bayestestR/reference/rope.html.


```{r Bayesian model, cache = TRUE}

bayes_model <- brm(ANSWER ~ TYPE * OBJform + (0 + TYPE * OBJform | subjects) + (1|items),
                   data = data,
                   bernoulli(link = "logit"),
                   warmup = 1000,
                   iter = 4000,
                   chains = 4,
                   control = list(adapt_delta = 0.99),
                   cores = parallel::detectCores())

bayes_model

bayestestR::equivalence_test(bayes_model)

```

```{r plot output}

plot(bayes_model, variable = "^b_", regex = TRUE)
ggsave("../Figures/EXP_2.bayes.pdf")

```

